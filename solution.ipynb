{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eye glasses detection\n",
    "\n",
    "In this project, we will create a binary eye-glasses detector.\n",
    "    We are going to use [CelebA dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html) as our dataset. This dataset has face attributes, one of these attributes is eyeglasses.\n",
    "\n",
    "## Intruduction\n",
    "\n",
    "### Guidelines\n",
    "\n",
    "Outline:\n",
    "\n",
    "1. Install face detector [DSFDDetector](https://github.com/hukkelas/DSFD-Pytorch-Inference)\n",
    "2. Crop faces using face detector\n",
    "3. Separate faces with glasses and those without glasses using the attributes\n",
    "4. build a train-dataloader and a test-dataloader (with 2 classes: `eyeglasses` `no-eyeglasses`)\n",
    "5. build and train the model\n",
    "6. evaluate the model\n",
    "\n",
    "You are allowed to and encouraged to browse the web for help.\n",
    "\n",
    "[PyTorch](https://pytorch.org/) is the preferred framework.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "You can solve this in any way, however you will be evaluated on the method you used.\n",
    "\n",
    "Evaluation will be based on:\n",
    "\n",
    "- code is functional (it works)\n",
    "- time\n",
    "- code is organized\n",
    "- bonus tasks\n",
    "\n",
    "\n",
    "### Tips\n",
    "\n",
    "- Use the internet!\n",
    "- Take your time reading, in fact go over the entire notebook first before writing anything\n",
    "- Ask for help if you get stuck\n",
    "- If one thing doesn't work, try something else (even if it's sub-optimal)\n",
    "- Check your output often, check the data shape makes sense and plot images to prevent confusion or errors\n",
    "- Keep track of time\n",
    "- Don't forget to enjoy and benefit from the excercise :)\n",
    "\n",
    "### Setup\n",
    "\n",
    "This is a [jupyter notebook](https://jupyter.org/),\n",
    "here are some [keyboard shortcuts](http://maxmelnick.com/2016/04/19/python-beginner-tips-and-tricks.html) to get you started.\n",
    "\n",
    "You can run terminal commands using `!` such as:\n",
    "\n",
    "```shell script\n",
    "!echo \"this is a command\"\n",
    "```\n",
    "\n",
    "### Workstation/PC specs\n",
    "\n",
    "The workstation you have is a [LambdaLabs](https://lambdalabs.com/deep-learning/workstations/2-gpu) dual RTX 8000 GPUs, each with 50GB of VRAM.  \n",
    "**It is advised to utilize both GPUs whenever possible to speedup computation**.\n",
    "\n",
    "To get more details, run `!nvidia-smi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus 1: Visualization (tensorboard is recommended)\n",
    "\n",
    "Visualize losses, and anything else that may be helpful\n",
    "\n",
    "## Bonus 2: Hyperparameter search (gridsearch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install [DSFD Face detector](https://github.com/hukkelas/DSFD-Pytorch-Inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloning https://github.com/hukkelas/DSFD-Pytorch-Inference\n",
    "! git clone https://github.com/hukkelas/DSFD-Pytorch-Inference.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd DSFD-Pytorch-Inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop faces\n",
    "\n",
    "Run the DSFD face detector to crop the faces (to make the problem easier to solve for our classifier)\n",
    "\n",
    "This part might take a while to run so **do** ask for help when you get here\n",
    "\n",
    "### Expected output\n",
    "\n",
    "A folder with cropped faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import face_detection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import concurrent.futures\n",
    "import itertools \n",
    "\n",
    "def get_face(img, detections):\n",
    "    if detections:\n",
    "        bboxes = [d[:4] for d in detections]\n",
    "        scores = [(b[2]-b[0])+(b[3]-b[1])for b in bboxes]\n",
    "        idx = np.argmax(scores)\n",
    "        bbox = bboxes[idx]\n",
    "        bbox = [int(num) for num in bbox]\n",
    "        face = img[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        return face[:, :, ::-1]\n",
    "    return []\n",
    "\n",
    "start_time = time.time()\n",
    "src_path = 'img_align_celeba/'\n",
    "dest_path = 'img_align_celeba_cropped'\n",
    "os.makedirs(dest_path, exist_ok=True)\n",
    "img_paths = glob.glob(f'{src_path}/*')\n",
    "\n",
    "\n",
    "detectors = [\n",
    "    face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3, device=f'cuda:{i}') \n",
    "    for i in range(torch.cuda.device_count())\n",
    "]\n",
    "\n",
    "def pred_dist(detector_idx, *args):\n",
    "    return detectors[detector_idx].batched_detect(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "for i in tqdm(range(len(img_paths)//batch_size), 'infering', unit='batch'):\n",
    "    img_p = img_paths[batch_size*i:batch_size*(i+1)]\n",
    "    \n",
    "    im = [cv2.imread(p)[:, :, ::-1] for p in img_p]\n",
    "    im = np.stack(im)\n",
    "    \n",
    "    batch_per_gpu = batch_size//len(detectors)\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executer:\n",
    "        imgs = [im[batch_per_gpu*i : batch_per_gpu*(i+1)] for i in range(len(detectors))]\n",
    "        detections += list(executer.map(pred_dist, list(range(len(detectors))), imgs))\n",
    "    \n",
    "    detections = [d.tolist() for d in detections]\n",
    "    faces = list(map(get_face, im, detections))\n",
    "\n",
    "    output_paths = [os.path.join(dest_path, p.split('/')[-1]) for p in img_p]\n",
    "    for output_path, face in zip(output_paths, faces):\n",
    "        if len(face) != 0:\n",
    "            try:\n",
    "                cv2.imwrite(output_path,face)\n",
    "            except:\n",
    "                print(face, output_path)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataloaders\n",
    "\n",
    "### Expected output:\n",
    "\n",
    "Train loader and test loader, each with 2 classes: `eyeglasses` and `no-eyeglasses`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "attributes_map_file = 'list_attr_celeba.txt'\n",
    "target_attribute = 'Eyeglasses'\n",
    "\n",
    "\n",
    "att = pd.read_csv(attributes_map_file, sep=\"  | \")\n",
    "Eyeglasses = att[target_attribute]\n",
    "Eyeglasses = Eyeglasses.replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_im = os.listdir('img_align_celeba_cropped/')\n",
    "data_dict = {im:Eyeglasses[im] for im in list_of_im}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(list(data_dict.keys()), list(data_dict.values()), test_size=0.1, stratify=list(data_dict.values()))\n",
    "d = {x:y for x,y in zip(x_train,y_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(y_train, x_train)[0]\n",
    "test_df = pd.DataFrame(y_test, index=x_test)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a classifier\n",
    "(transfer learning is recommended)\n",
    "\n",
    "### Expected output\n",
    "\n",
    "a pytorch classifier model to classify `eyeglasses` vs `no-eyeglasses`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eyeglasses_data(Dataset):\n",
    "    def __init__(self, root, data_frame, transform=None):\n",
    "        super(Eyeglasses_data, self).__init__()\n",
    "        self.root = root\n",
    "        self.data_frame = data_frame\n",
    "        self.keys = data_frame.keys()\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        im_name = self.keys[idx]\n",
    "        im_path = os.path.join(self.root, im_name)\n",
    "        label = self.data_frame[im_name]\n",
    "        image = plt.imread(im_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                    transforms.ToPILImage(),\n",
    "                                    transforms.Resize((200,200)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ColorJitter(brightness=(0.5)),\n",
    "                                    transforms.ToTensor()\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "                                    transforms.ToPILImage(),\n",
    "                                    transforms.Resize((200,200)),\n",
    "                                    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = Eyeglasses_data('img_align_celeba_cropped/', train_df, transform=train_transforms)\n",
    "trainloader = DataLoader(train_dataset, batch_size=256)\n",
    "\n",
    "test_dataset = Eyeglasses_data('img_align_celeba_cropped/', test_df, transform=test_transforms)\n",
    "testloader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "### Expected output:\n",
    "\n",
    "a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.num_classes = params['num_classes']\n",
    "        self.classifier = nn.Linear(1000, self.num_classes)\n",
    "        self.feature_extractor = torchvision.models.resnet18(pretrained=True)\n",
    "        self.change_training_state_of_feature_extractor(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "    def change_training_state_of_feature_extractor(self, state):\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():    \n",
    "    def __init__(self, model, trainloader, testloader, params):\n",
    "        self.epoch = 0\n",
    "        self.print_every = 10\n",
    "        self.iter_counter = 0\n",
    "        self.trainloader, self.testloader = trainloader, testloader\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.params = params\n",
    "        self.exp_name = '___'.join(['']+[f'{k}={v}' for k,v in params.items()])\n",
    "        print(f'executing:  {self.exp_name}')\n",
    "        self.summarywriter = SummaryWriter(comment=self.exp_name)\n",
    "        \n",
    "        self.create_optimizer()\n",
    "        weight = self.calculate_weight()\n",
    "        weight = torch.tensor([0.9349, 0.0651])\n",
    "        if self.params['loss_function'] == 'cross_entropy':\n",
    "            weight = weight.to(self.device)\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=weight).to(self.device)\n",
    "        else:\n",
    "            raise Exception('unknown loss function!')\n",
    "        \n",
    "    def train(self):\n",
    "        self.running_loss = 0.0\n",
    "        for self.epoch in range(self.params['n_epochs']):\n",
    "            if self.epoch == 0:\n",
    "                self.model.change_training_state_of_feature_extractor(True)\n",
    "            for inputs, labels in self.trainloader:\n",
    "                self.iter_counter += 1\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                self.running_loss += loss.item()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if self.iter_counter % self.print_every == 0:\n",
    "                    self.print_progress()\n",
    "            self.test()\n",
    "        \n",
    "    def test(self):\n",
    "        all_pred = torch.empty(0)\n",
    "        all_labels = torch.empty(0)\n",
    "        self.model.eval()\n",
    "        for i, (inputs, labels) in enumerate(self.testloader):\n",
    "            inputs, labels = inputs.to(trainer.device), labels.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels = torch.cat((all_labels, labels.cpu()))\n",
    "            all_pred = torch.cat((all_pred, predicted.cpu()))\n",
    "        accuracy = 100 * (all_pred == all_labels).sum().item()/all_labels.size()[0]\n",
    "        self.summarywriter.add_scalar('test accuracy', accuracy, self.epoch)\n",
    "        print(f'accuracy= {accuracy}')\n",
    "        conf_mat = sklearn.metrics.confusion_matrix(all_labels, all_pred)\n",
    "        print('confusion matrix', conf_mat)\n",
    "        self.save_model()\n",
    "        self.model.train()\n",
    "        \n",
    "    def create_optimizer(self):\n",
    "        if self.params['optimizer'] == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.params['learning_rate'])\n",
    "        elif self.params['optimizer'] == 'adam':\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.params['learning_rate'])\n",
    "        else:\n",
    "            raise Exception('Unknown optimizer!')\n",
    "\n",
    "    def save_model(self):\n",
    "        saving_dir = f'runs/{self.exp_name}/saved_models'\n",
    "        os.makedirs(saving_dir, exist_ok=True)\n",
    "        path = os.path.join(saving_dir, f'epoch_{self.epoch}_iter_{self.iter_counter}.pth')\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        \n",
    "    def calculate_weight(self):\n",
    "        weight = torch.zeros(self.params['num_classes'], dtype=torch.float32)\n",
    "        for _, label in self.trainloader:\n",
    "            weight += torch.nn.functional.one_hot(label, num_classes=self.params['num_classes']).sum(0)\n",
    "        return weight/weight.sum()\n",
    "    \n",
    "    def print_progress(self):\n",
    "        avg_loss = self.running_loss / self.print_every\n",
    "        print(f'epoch = {self.epoch+1}    iter = {self.iter_counter}     loss = {avg_loss:.5f}')\n",
    "        self.summarywriter.add_scalar('loss', avg_loss, (self.epoch+1)*self.iter_counter)\n",
    "        self.running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_classes':2,\n",
    "    'n_epochs':5,\n",
    "    'batch_size':256,\n",
    "    'optimizer':'adam',\n",
    "    'learning_rate':0.0001,\n",
    "    'loss_function':'cross_entropy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Classifier(params)\n",
    "trainer = Trainer(classifier, trainloader, testloader, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run training ...\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run testing ...\n",
    "\n",
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
