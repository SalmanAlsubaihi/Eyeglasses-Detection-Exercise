{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of stuff\n",
    "jupyter links\n",
    "pc specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloning https://github.com/hukkelas/DSFD-Pytorch-Inference\n",
    "! git clone https://github.com/hukkelas/DSFD-Pytorch-Inference.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd DSFD-Pytorch-Inference/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tip:\n",
    "- plot 1 outpu first\n",
    "- should take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### crop faces\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import face_detection\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "import concurrent.futures\n",
    "\n",
    "def get_face(img, detections):\n",
    "    if detections:\n",
    "        bboxes = [d[:4] for d in detections]\n",
    "        scores = [(b[2]-b[0])+(b[3]-b[1])for b in bboxes]\n",
    "        idx = np.argmax(scores)\n",
    "        bbox = bboxes[idx]\n",
    "        bbox = [int(num) for num in bbox]\n",
    "        face = img[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        return face[:, :, ::-1]\n",
    "    return []\n",
    "\n",
    "start_time = time.time()\n",
    "src_path = 'img_align_celeba/'\n",
    "dest_path = 'img_align_celeba_cropped'\n",
    "os.makedirs(dest_path, exist_ok=True)\n",
    "img_paths = glob.glob(f'{src_path}/*')\n",
    "\n",
    "\n",
    "detectors = [\n",
    "    face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3, device=f'cuda:{i}') \n",
    "    for i in range(torch.cuda.device_count())\n",
    "]\n",
    "\n",
    "def pred_dist(detector_idx, *args):\n",
    "    return detectors[detector_idx].batched_detect(*args)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools \n",
    "\n",
    "\n",
    "batch_size = 200\n",
    "for i in tqdm(range(len(img_paths)//batch_size), 'infering', unit='batch'):\n",
    "    img_p = img_paths[batch_size*i:batch_size*(i+1)]\n",
    "    \n",
    "    im = [cv2.imread(p)[:, :, ::-1] for p in img_p]\n",
    "    im = np.stack(im)\n",
    "    \n",
    "    batch_per_gpu = batch_size//len(detectors)\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executer:\n",
    "        imgs = [im[batch_per_gpu*i : batch_per_gpu*(i+1)] for i in range(len(detectors))]\n",
    "        detections += list(executer.map(pred_dist, list(range(len(detectors))), imgs))\n",
    "        \n",
    "#     det = []\n",
    "#     for d in detections:\n",
    "#         det.extend(d)\n",
    "#     detections = det\n",
    "    \n",
    "    detections = [d.tolist() for d in detections]\n",
    "    faces = list(map(get_face, im, detections))\n",
    "\n",
    "    output_paths = [os.path.join(dest_path, p.split('/')[-1]) for p in img_p]\n",
    "    for output_path, face in zip(output_paths, faces):\n",
    "        if len(face) != 0:\n",
    "            try:\n",
    "                cv2.imwrite(output_path,face)\n",
    "            except:\n",
    "                print(face, output_path)\n",
    "\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raied/anaconda3/envs/test/lib/python3.7/site-packages/ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "att = pd.read_csv('list_attr_celeba.txt', sep=\"  | \")\n",
    "Eyeglasses = att['Eyeglasses']\n",
    "Eyeglasses = Eyeglasses.replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "list_of_im = os.listdir('img_align_celeba_cropped/')\n",
    "data_dict = {im:Eyeglasses[im] for im in list_of_im}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/raied/anaconda3/envs/test/lib/python3.7/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/raied/anaconda3/envs/test/lib/python3.7/site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/raied/anaconda3/envs/test/lib/python3.7/site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/raied/anaconda3/envs/test/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.19.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/raied/anaconda3/envs/test/lib/python3.7/site-packages (from scikit-learn->sklearn) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/raied/anaconda3/envs/test/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.5.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(list(data_dict.keys()), list(data_dict.values()), test_size=0.1, stratify=list(data_dict.values()))\n",
    "d = {x:y for x,y in zip(x_train,y_train)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(y_train, x_train)[0]\n",
    "test_df = pd.DataFrame(y_test, index=x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eyeglasses_data(Dataset):\n",
    "    def __init__(self, root, data_frame, transform=None):\n",
    "        super(Eyeglasses_data, self).__init__()\n",
    "        self.root = root\n",
    "        self.data_frame = data_frame\n",
    "        self.keys = data_frame.keys()\n",
    "        self.transform = transform\n",
    "    def __getitem__(self, idx):\n",
    "        im_name = self.keys[idx]\n",
    "        im_path = os.path.join(self.root, im_name)\n",
    "        label = self.data_frame[im_name]\n",
    "        image = plt.imread(im_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                                    transforms.ToPILImage(),\n",
    "                                    transforms.Resize((200,200)),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ColorJitter(brightness=(0.5)),\n",
    "                                    transforms.ToTensor()\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "                                    transforms.ToPILImage(),\n",
    "                                    transforms.Resize((200,200)),\n",
    "                                    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = Eyeglasses_data('img_align_celeba_cropped/', train_df, transform=train_transforms)\n",
    "trainloader = DataLoader(train_dataset, batch_size=256)\n",
    "\n",
    "test_dataset = Eyeglasses_data('img_align_celeba_cropped/', test_df, transform=test_transforms)\n",
    "testloader = DataLoader(test_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sklearn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.num_classes = params['num_classes']\n",
    "        self.classifier = nn.Linear(1000, self.num_classes)\n",
    "        self.feature_extractor = torchvision.models.resnet18(pretrained=True)\n",
    "        self.change_training_state_of_feature_extractor(False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        logits = self.classifier(features)\n",
    "        return logits\n",
    "\n",
    "    def change_training_state_of_feature_extractor(self, state):\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():    \n",
    "    def __init__(self, model, trainloader, testloader, params):\n",
    "        self.epoch = 0\n",
    "        self.print_every = 10\n",
    "        self.iter_counter = 0\n",
    "        self.trainloader, self.testloader = trainloader, testloader\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.params = params\n",
    "        self.exp_name = '___'.join(['']+[f'{k}={v}' for k,v in params.items()])\n",
    "        print(f'executing:  {self.exp_name}')\n",
    "        self.summarywriter = SummaryWriter(comment=self.exp_name)\n",
    "        \n",
    "        self.create_optimizer()\n",
    "#         weight = self.calculate_weight()\n",
    "        weight = torch.tensor([0.9349, 0.0651])\n",
    "        if self.params['loss_function'] == 'cross_entropy':  ############## improve\n",
    "            weight = weight.to(self.device)\n",
    "            self.criterion = nn.CrossEntropyLoss(weight=weight).to(self.device)\n",
    "        else:\n",
    "            raise Exception('unknown loss function!')\n",
    "        \n",
    "    def train(self):\n",
    "        self.running_loss = 0.0\n",
    "        for self.epoch in range(self.params['n_epochs']):\n",
    "            if self.epoch == 0:\n",
    "                self.model.change_training_state_of_feature_extractor(True)\n",
    "            for inputs, labels in self.trainloader:\n",
    "                self.iter_counter += 1\n",
    "                inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(inputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                self.running_loss += loss.item()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if self.iter_counter % self.print_every == 0:\n",
    "                    self.print_progress()\n",
    "            self.test()\n",
    "        \n",
    "    def test(self):\n",
    "        all_pred = torch.empty(0)\n",
    "        all_labels = torch.empty(0)\n",
    "        self.model.eval()\n",
    "        for i, (inputs, labels) in enumerate(self.testloader):\n",
    "            inputs, labels = inputs.to(trainer.device), labels.to(self.device)\n",
    "            outputs = self.model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            all_labels = torch.cat((all_labels, labels.cpu()))\n",
    "            all_pred = torch.cat((all_pred, predicted.cpu()))\n",
    "        accuracy = 100 * (all_pred == all_labels).sum().item()/all_labels.size()[0]\n",
    "        self.summarywriter.add_scalar('test accuracy', accuracy, self.epoch)\n",
    "        print(f'accuracy= {accuracy}')\n",
    "        conf_mat = sklearn.metrics.confusion_matrix(all_labels, all_pred)\n",
    "        print('confusion matrix', conf_mat)\n",
    "        self.save_model()\n",
    "        self.model.train()\n",
    "        \n",
    "    def create_optimizer(self):   ############## improve\n",
    "        if self.params['optimizer'] == 'SGD':\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.params['learning_rate'])\n",
    "        elif self.params['optimizer'] == 'adam':\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.params['learning_rate'])\n",
    "        else:\n",
    "            raise Exception('Unknown optimizer!')\n",
    "\n",
    "    def save_model(self):\n",
    "        saving_dir = f'runs/{self.exp_name}/saved_models'\n",
    "        os.makedirs(saving_dir, exist_ok=True)\n",
    "        path = os.path.join(saving_dir, f'epoch_{self.epoch}_iter_{self.iter_counter}.pth')\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "        \n",
    "    def calculate_weight(self):\n",
    "        weight = torch.zeros(self.params['num_classes'], dtype=torch.float32)\n",
    "        for _, label in self.trainloader:\n",
    "            weight += torch.nn.functional.one_hot(label, num_classes=self.params['num_classes']).sum(0)\n",
    "        return weight/weight.sum()\n",
    "    \n",
    "    def print_progress(self):\n",
    "        avg_loss = self.running_loss / self.print_every\n",
    "        print(f'epoch = {self.epoch+1}    iter = {self.iter_counter}     loss = {avg_loss:.5f}')\n",
    "        self.summarywriter.add_scalar('loss', avg_loss, (self.epoch+1)*self.iter_counter)\n",
    "        self.running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'num_classes':2,\n",
    "    'n_epochs':5,\n",
    "    'batch_size':256,\n",
    "    'optimizer':'adam',\n",
    "    'learning_rate':0.0001,\n",
    "    'loss_function':'cross_entropy'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing:  ___num_classes=2___n_epochs=5___batch_size=256___optimizer=adam___learning_rate=0.0001___loss_function=cross_entropy\n"
     ]
    }
   ],
   "source": [
    "classifier = Classifier(params)\n",
    "trainer = Trainer(classifier, trainloader, testloader, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy= 6.582003261352967\n",
      "confusion matrix [[   18 18901]\n",
      " [    4  1314]]\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 1    iter = 10     loss = 0.18204\n",
      "epoch = 1    iter = 20     loss = 0.00972\n",
      "epoch = 1    iter = 30     loss = 0.00544\n",
      "epoch = 1    iter = 40     loss = 0.00531\n",
      "epoch = 1    iter = 50     loss = 0.00563\n",
      "epoch = 1    iter = 60     loss = 0.00779\n",
      "epoch = 1    iter = 70     loss = 0.00464\n",
      "epoch = 1    iter = 80     loss = 0.00586\n",
      "epoch = 1    iter = 90     loss = 0.00453\n",
      "epoch = 1    iter = 100     loss = 0.00548\n",
      "epoch = 1    iter = 110     loss = 0.00411\n",
      "epoch = 1    iter = 120     loss = 0.00345\n",
      "epoch = 1    iter = 130     loss = 0.00263\n",
      "epoch = 1    iter = 140     loss = 0.00297\n",
      "epoch = 1    iter = 150     loss = 0.00309\n",
      "epoch = 1    iter = 160     loss = 0.00504\n",
      "epoch = 1    iter = 170     loss = 0.00626\n",
      "epoch = 1    iter = 180     loss = 0.00579\n",
      "epoch = 1    iter = 190     loss = 0.00567\n",
      "epoch = 1    iter = 200     loss = 0.00715\n",
      "epoch = 1    iter = 210     loss = 0.00361\n",
      "epoch = 1    iter = 220     loss = 0.00354\n",
      "epoch = 1    iter = 230     loss = 0.00352\n",
      "epoch = 1    iter = 240     loss = 0.00499\n",
      "epoch = 1    iter = 250     loss = 0.00434\n",
      "epoch = 1    iter = 260     loss = 0.00510\n",
      "epoch = 1    iter = 270     loss = 0.00509\n",
      "epoch = 1    iter = 280     loss = 0.00326\n",
      "epoch = 1    iter = 290     loss = 0.00387\n",
      "epoch = 1    iter = 300     loss = 0.00249\n",
      "epoch = 1    iter = 310     loss = 0.00567\n",
      "epoch = 1    iter = 320     loss = 0.00311\n",
      "epoch = 1    iter = 330     loss = 0.00299\n",
      "epoch = 1    iter = 340     loss = 0.00759\n",
      "epoch = 1    iter = 350     loss = 0.00638\n",
      "epoch = 1    iter = 360     loss = 0.00467\n",
      "epoch = 1    iter = 370     loss = 0.00244\n",
      "epoch = 1    iter = 380     loss = 0.00378\n",
      "epoch = 1    iter = 390     loss = 0.00466\n",
      "epoch = 1    iter = 400     loss = 0.00681\n",
      "epoch = 1    iter = 410     loss = 0.00447\n",
      "epoch = 1    iter = 420     loss = 0.00364\n",
      "epoch = 1    iter = 430     loss = 0.00296\n",
      "epoch = 1    iter = 440     loss = 0.00371\n",
      "epoch = 1    iter = 450     loss = 0.00316\n",
      "epoch = 1    iter = 460     loss = 0.00610\n",
      "epoch = 1    iter = 470     loss = 0.00439\n",
      "epoch = 1    iter = 480     loss = 0.00310\n",
      "epoch = 1    iter = 490     loss = 0.00267\n",
      "epoch = 1    iter = 500     loss = 0.00576\n",
      "epoch = 1    iter = 510     loss = 0.00334\n",
      "epoch = 1    iter = 520     loss = 0.00722\n",
      "epoch = 1    iter = 530     loss = 0.00480\n",
      "epoch = 1    iter = 540     loss = 0.00278\n",
      "epoch = 1    iter = 550     loss = 0.00211\n",
      "epoch = 1    iter = 560     loss = 0.00386\n",
      "epoch = 1    iter = 570     loss = 0.00281\n",
      "epoch = 1    iter = 580     loss = 0.00113\n",
      "epoch = 1    iter = 590     loss = 0.00346\n",
      "epoch = 1    iter = 600     loss = 0.00093\n",
      "epoch = 1    iter = 610     loss = 0.00278\n",
      "epoch = 1    iter = 620     loss = 0.00144\n",
      "epoch = 1    iter = 630     loss = 0.00121\n",
      "epoch = 1    iter = 640     loss = 0.00394\n",
      "epoch = 1    iter = 650     loss = 0.00243\n",
      "epoch = 1    iter = 660     loss = 0.00319\n",
      "epoch = 1    iter = 670     loss = 0.00275\n",
      "epoch = 1    iter = 680     loss = 0.00443\n",
      "epoch = 1    iter = 690     loss = 0.00370\n",
      "epoch = 1    iter = 700     loss = 0.00322\n",
      "epoch = 1    iter = 710     loss = 0.00531\n",
      "accuracy= 99.1401887631566\n",
      "confusion matrix [[18906    13]\n",
      " [  161  1157]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-88-99d78cac1a23>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_counter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-88-99d78cac1a23>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'confusion matrix'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'save_model' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs= 5\n",
      "model= tacotron2\n",
      "args ()\n",
      "kwargs {'bekfast': True}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func(epochs, model, *args, **kwargs):\n",
    "    print(\"epochs=\", epochs)\n",
    "    print(\"model=\", model)\n",
    "    \n",
    "    print('args', args)\n",
    "    print('kwargs', kwargs)\n",
    "    \n",
    "    return kwargs['bekfast']\n",
    "\n",
    "\n",
    "config = {'epochs': 5, 'model': 'tacotron2', 'bekfast':True}\n",
    "\n",
    "func(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.add_scalar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
